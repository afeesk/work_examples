{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and Load Dataset to s3 target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of ths solution is to create a Python script that enables the reading and loading of data to an Amazon s3 bucket. This script provides an easy-to-use and efficient way to handle data movement to and from s3 bucket. The python script reads data from a local directory and load it to a specific s3 bucket. The script supports CSV and Parquet files and writing of Parquet files to s3. It also supports reading Parquet file from the s3 bucket.\n",
    "\n",
    "The solution leverages the Boto3 Python library to connect to the s3 bucket, and it can be easily configured using the configuration file or environmental variables. The solution offers a convenient way to automate data pipeline tasks and reduce manual effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataETL import DataETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataETL in module dataETL:\n",
      "\n",
      "class DataETL(builtins.object)\n",
      " |  DataETL(bucket_name, bucket_folder=None, source_path=None)\n",
      " |  \n",
      " |  A class for extracting data from a local folder and loading into s3 target.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, bucket_name, bucket_folder=None, source_path=None)\n",
      " |      :param bucket_name: The name of the s3 bucket to read from or write to.\n",
      " |      :param bucket_folder: str, None\n",
      " |                            The folder name in the bucket to write the file to or read from.\n",
      " |                            Default is None\n",
      " |      : param source_path: str, None\n",
      " |                           The path to the local folder to extract data from.\n",
      " |                           Default is None\n",
      " |  \n",
      " |  extract_data_from_s3(self, file_key: str) -> pandas.core.frame.DataFrame\n",
      " |      Extract data from an s3 bucket.\n",
      " |      :return: The dataset as a pandas dataFrame.\n",
      " |  \n",
      " |  list_s3_files(self)\n",
      " |      List the files on the s3 bucket.\n",
      " |      :return: The list of file key(s) of the files and folders available on the s3 bucket.\n",
      " |  \n",
      " |  load_data_to_s3(self)\n",
      " |      Save the locally extracted data to the s3 bucket.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DataETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a datasets folder in the same location where the script is stored and add the datasets that need to be uploaded to the s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(), 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'test-s3-etl-001'\n",
    "BUCKET_FOLDER = 'folder-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataETL(source_path=DATA_PATH, bucket_name=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the s3 bucket name is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the files available on the s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['folder-01/']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.list_s3_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data to the s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2023-04-28 15:06:57,375 - WARNING - Skipping geometry.xlsx, we don't currently support xlsx\n",
      " 2023-04-28 15:06:57,376 - INFO - Extracting Product Lookup data...\n",
      " 2023-04-28 15:06:57,387 - INFO - Extracting Store Lookup data...\n",
      " 2023-04-28 15:06:57,393 - INFO - Extraction completed\n",
      " 2023-04-28 15:06:57,393 - INFO - Loading Product Lookup data to s3...\n",
      " 2023-04-28 15:06:57,815 - INFO - Loading Store Lookup data to s3...\n",
      " 2023-04-28 15:06:58,177 - INFO - Loading completed\n"
     ]
    }
   ],
   "source": [
    "data.load_data_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_s3 = DataETL(bucket_name=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the files available on the s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product Lookup.parquet', 'Store Lookup.parquet', 'folder-01/']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_s3.list_s3_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the required file from the s3 bucket using the file name as the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2023-04-28 15:07:01,640 - INFO - Extracting Product Lookup.parquet data from s3...\n",
      " 2023-04-28 15:07:01,882 - INFO - Extraction completed\n"
     ]
    }
   ],
   "source": [
    "df = data_from_s3.extract_data_from_s3(file_key='Product Lookup.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_group</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product</th>\n",
       "      <th>product_description</th>\n",
       "      <th>unit_of_measure</th>\n",
       "      <th>current_cost</th>\n",
       "      <th>current_wholesale_price</th>\n",
       "      <th>current_retail_price</th>\n",
       "      <th>tax_exempt_yn</th>\n",
       "      <th>promo_yn</th>\n",
       "      <th>new_product_yn</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Whole Bean/Teas</td>\n",
       "      <td>Coffee beans</td>\n",
       "      <td>Organic Beans</td>\n",
       "      <td>Brazilian - Organic</td>\n",
       "      <td>It's like Carnival in a cup. Clean and smooth.</td>\n",
       "      <td>12 oz</td>\n",
       "      <td>3.60</td>\n",
       "      <td>14.40</td>\n",
       "      <td>18.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Whole Bean/Teas</td>\n",
       "      <td>Coffee beans</td>\n",
       "      <td>House blend Beans</td>\n",
       "      <td>Our Old Time Diner Blend</td>\n",
       "      <td>Out packed blend of beans that is reminiscent ...</td>\n",
       "      <td>12 oz</td>\n",
       "      <td>3.60</td>\n",
       "      <td>14.40</td>\n",
       "      <td>18.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Whole Bean/Teas</td>\n",
       "      <td>Coffee beans</td>\n",
       "      <td>Espresso Beans</td>\n",
       "      <td>Espresso Roast</td>\n",
       "      <td>Our house blend for a good espresso shot.</td>\n",
       "      <td>1 lb</td>\n",
       "      <td>2.95</td>\n",
       "      <td>11.80</td>\n",
       "      <td>14.75</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Whole Bean/Teas</td>\n",
       "      <td>Coffee beans</td>\n",
       "      <td>Espresso Beans</td>\n",
       "      <td>Primo Espresso Roast</td>\n",
       "      <td>Our primium single source of hand roasted beans.</td>\n",
       "      <td>1 lb</td>\n",
       "      <td>4.09</td>\n",
       "      <td>16.36</td>\n",
       "      <td>20.45</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Whole Bean/Teas</td>\n",
       "      <td>Coffee beans</td>\n",
       "      <td>Gourmet Beans</td>\n",
       "      <td>Columbian Medium Roast</td>\n",
       "      <td>A smooth cup of coffee any time of day.</td>\n",
       "      <td>1 lb</td>\n",
       "      <td>3.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id    product_group product_category       product_type   \n",
       "0           1  Whole Bean/Teas     Coffee beans      Organic Beans  \\\n",
       "1           2  Whole Bean/Teas     Coffee beans  House blend Beans   \n",
       "2           3  Whole Bean/Teas     Coffee beans     Espresso Beans   \n",
       "3           4  Whole Bean/Teas     Coffee beans     Espresso Beans   \n",
       "4           5  Whole Bean/Teas     Coffee beans      Gourmet Beans   \n",
       "\n",
       "                    product   \n",
       "0       Brazilian - Organic  \\\n",
       "1  Our Old Time Diner Blend   \n",
       "2            Espresso Roast   \n",
       "3      Primo Espresso Roast   \n",
       "4    Columbian Medium Roast   \n",
       "\n",
       "                                 product_description unit_of_measure   \n",
       "0     It's like Carnival in a cup. Clean and smooth.           12 oz  \\\n",
       "1  Out packed blend of beans that is reminiscent ...           12 oz   \n",
       "2          Our house blend for a good espresso shot.            1 lb   \n",
       "3   Our primium single source of hand roasted beans.            1 lb   \n",
       "4           A smooth cup of coffee any time of day.             1 lb   \n",
       "\n",
       "   current_cost  current_wholesale_price  current_retail_price tax_exempt_yn   \n",
       "0          3.60                    14.40                 18.00             Y  \\\n",
       "1          3.60                    14.40                 18.00             Y   \n",
       "2          2.95                    11.80                 14.75             Y   \n",
       "3          4.09                    16.36                 20.45             Y   \n",
       "4          3.00                    12.00                 15.00             Y   \n",
       "\n",
       "  promo_yn new_product_yn  Unnamed: 13  \n",
       "0        N              N          NaN  \n",
       "1        N              N          NaN  \n",
       "2        N              N          NaN  \n",
       "3        N              N          NaN  \n",
       "4        N              N          NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets to a folder on the s3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the target location is a first level folder on the s3 bucket, then you need an additional argument to set the bucket_folder to that folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataETL(source_path=DATA_PATH, bucket_name=BUCKET_NAME, bucket_folder=BUCKET_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2023-04-28 15:07:05,187 - WARNING - Skipping geometry.xlsx, we don't currently support xlsx\n",
      " 2023-04-28 15:07:05,189 - INFO - Extracting Product Lookup data...\n",
      " 2023-04-28 15:07:05,195 - INFO - Extracting Store Lookup data...\n",
      " 2023-04-28 15:07:05,199 - INFO - Extraction completed\n",
      " 2023-04-28 15:07:05,201 - INFO - Loading Product Lookup data to s3...\n",
      " 2023-04-28 15:07:06,223 - INFO - Loading Store Lookup data to s3...\n",
      " 2023-04-28 15:07:06,609 - INFO - Loading completed\n"
     ]
    }
   ],
   "source": [
    "data.load_data_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data from the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_s3 = DataETL(bucket_name=BUCKET_NAME, bucket_folder=BUCKET_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the files available on the s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product Lookup.parquet',\n",
       " 'Store Lookup.parquet',\n",
       " 'folder-01/',\n",
       " 'folder-01/Product Lookup.parquet',\n",
       " 'folder-01/Store Lookup.parquet']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_s3.list_s3_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the required file from the folder on s3 bucket using the file name as the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2023-04-28 15:07:09,854 - INFO - Extracting Store Lookup.parquet data from s3...\n",
      " 2023-04-28 15:07:09,999 - INFO - Extraction completed\n"
     ]
    }
   ],
   "source": [
    "df2 = data_from_s3.extract_data_from_s3(file_key='Store Lookup.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_type</th>\n",
       "      <th>store_square_feet</th>\n",
       "      <th>store_address</th>\n",
       "      <th>store_city</th>\n",
       "      <th>store_state_province</th>\n",
       "      <th>store_postal_code</th>\n",
       "      <th>store_longitude</th>\n",
       "      <th>store_latitude</th>\n",
       "      <th>manager</th>\n",
       "      <th>Neighorhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>3400</td>\n",
       "      <td>164-14 Jamaica Ave</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>NY</td>\n",
       "      <td>11432</td>\n",
       "      <td>-73.795168</td>\n",
       "      <td>40.705226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jamaica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>retail</td>\n",
       "      <td>1300</td>\n",
       "      <td>32-20 Broadway</td>\n",
       "      <td>Long Island City</td>\n",
       "      <td>NY</td>\n",
       "      <td>11106</td>\n",
       "      <td>-73.924008</td>\n",
       "      <td>40.761196</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Astoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>retail</td>\n",
       "      <td>900</td>\n",
       "      <td>100 Church Street</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10007</td>\n",
       "      <td>-74.010130</td>\n",
       "      <td>40.713290</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Lower Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>retail</td>\n",
       "      <td>1500</td>\n",
       "      <td>687 9th Avenue</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10036</td>\n",
       "      <td>-73.990338</td>\n",
       "      <td>40.761887</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id store_type  store_square_feet       store_address   \n",
       "0         2  warehouse               3400  164-14 Jamaica Ave  \\\n",
       "1         3     retail               1300      32-20 Broadway   \n",
       "2         5     retail                900   100 Church Street   \n",
       "3         8     retail               1500      687 9th Avenue   \n",
       "\n",
       "         store_city store_state_province  store_postal_code  store_longitude   \n",
       "0           Jamaica                   NY              11432       -73.795168  \\\n",
       "1  Long Island City                   NY              11106       -73.924008   \n",
       "2          New York                   NY              10007       -74.010130   \n",
       "3          New York                   NY              10036       -73.990338   \n",
       "\n",
       "   store_latitude  manager      Neighorhood  \n",
       "0       40.705226      NaN          Jamaica  \n",
       "1       40.761196      6.0          Astoria  \n",
       "2       40.713290     16.0  Lower Manhattan  \n",
       "3       40.761887     31.0   Hell's Kitchen  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
